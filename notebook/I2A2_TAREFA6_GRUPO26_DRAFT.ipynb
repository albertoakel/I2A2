{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiSikK__wiqY"
   },
   "source": [
    "# **&#9776; DESAFIO VI**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeOlLahi9dH5"
   },
   "source": [
    "# **:: Leitura Inicial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pv2lqp59G-5"
   },
   "source": [
    "<h4 align=\"justify\">Para o Desafio 6, todos os grupos deverão realizar a leitura do texto abaixo como parte do momento de reflexão. Para acessar o conteúdo, clique no link disponibilizado a seguir.</h4>\n",
    "<a href=\"https://cop.dol.com.br/amazonia/o-que-fazer-com-aquele-eletronico-que-nao-serve-mais/7682/\" target=\"_blank\">Saiba o que fazer com aquele eletrônico que não serve mais</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgrPBXW1CGJ4"
   },
   "source": [
    "# **:: Contextualização do Desafio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQRU3qQ1COIL"
   },
   "source": [
    "<h4 align=\"justify\">A Amazônia é conhecida mundialmente por sua biodiversidade e pela importância vital para o equilíbrio climático do planeta. No entanto, para além do desmatamento e da poluição dos rios, existe uma ameaça crescente e silenciosa que também chega à região: o lixo eletrônico. Computadores, celulares, televisores, pilhas e baterias descartados de forma incorreta liberam metais pesados, como mercúrio, chumbo e cádmio, contaminando solo, rios e entrando na cadeia alimentar que sustenta populações inteiras.</h4>\n",
    "<h4 align=\"justify\">Esse problema não é exclusivo da Amazônia, mas ganha contornos mais graves no território amazônico, onde a logística de transporte e a ausência de infraestrutura adequada tornam o descarte ainda mais desafiador. Muitas vezes, equipamentos quebrados acabam abandonados em áreas urbanas, lixões ou até mesmo despejados em rios, ampliando os riscos ambientais e de saúde pública.</h4>\n",
    "<h4 align=\"justify\">Relatórios internacionais já apontam o Brasil como um dos maiores produtores de lixo eletrônico do mundo, com índices de reciclagem muito abaixo do ideal. Dentro desse cenário, o papel dos Tecnoguardas da Amazônia é analisar os dados disponíveis e propor soluções baseadas em evidências, que ajudem a transformar informação em ação prática para reduzir os danos ambientais.</h4>\n",
    "<h4 align=\"justify\">Para enfrentar esse desafio, vocês receberão uma base de dados fictícia inspirada em situações reais de descarte de lixo eletrônico na Amazônia. O dataset contém informações sobre diferentes tipos de eletrônicos descartados, suas origens, possíveis destinos, além de indicadores socioambientais. Porém, como ocorre na vida real, esses dados não estão limpos: há registros incompletos, duplicados, inconsistentes e com ruídos que dificultarão a análise.</h4>\n",
    "<h4 align=\"justify\">A missão exige que vocês usem todas as habilidades adquiridas no Bloco 4 – Manipulação e Visualização de Dados. Será necessário trabalhar com Pandas para explorar, tratar e transformar os dados; aplicar agrupamentos e agregações para identificar padrões relevantes; e utilizar bibliotecas de visualização como Matplotlib e Seaborn para comunicar insights de maneira clara e impactante.</h4>\n",
    "<h4 align=\"justify\">A dificuldade não estará apenas na manipulação dos dados, mas também em interpretar o que eles significam em termos ambientais e sociais. Como bons Tecnoguardas, vocês devem ser capazes de enxergar além dos números: perceber tendências, apontar riscos e até sugerir ações preventivas que poderiam ser aplicadas por governos, ONGs ou comunidades locais.</h4>\n",
    "<h4 align=\"justify\">O <b>Desafio 6 é um desafio de nível elevado</b> porque vai exigir resiliência, pensamento crítico e criatividade. Não será suficiente aplicar funções básicas de Pandas ou gerar gráficos simples. Vocês precisarão testar hipóteses, organizar relatórios visuais coerentes e lidar com a frustração de trabalhar com dados imperfeitos — exatamente como ocorre no mundo real da ciência de dados aplicada à sustentabilidade.</h4>\n",
    "<h4 align=\"justify\">Ao final, o objetivo é que cada equipe consiga <b>apresentar um diagnóstico robusto sobre o cenário do lixo eletrônico na Amazônia, baseado na base fornecida</b>. Esse diagnóstico deve se apoiar em análises exploratórias profundas, combinações de variáveis, comparações entre grupos e visualizações poderosas, capazes de sensibilizar qualquer tomador de decisão sobre a urgência de enfrentar o problema.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZu7iRWPTKHX"
   },
   "source": [
    "# **:: Estrutura da Base de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikz4_g_CTOHN"
   },
   "source": [
    "### A base fictícia conterá 150 instâncias com as seguintes variáveis:\n",
    "\n",
    "\n",
    "**ID_Registro** – Identificador único\n",
    "\n",
    "**Tipo_Eletronico** – Categoria do item (celular, computador, TV, bateria, etc.)\n",
    "\n",
    "**Ano_Fabricacao** – Ano de fabricação do dispositivo\n",
    "\n",
    "**Origem** – Origem do descarte (urbana, rural, industrial, governamental)\n",
    "\n",
    "**Destino_Final** – Local de descarte (cooperativa, lixão, reciclagem formal, rio, aterro controlado)\n",
    "\n",
    "**Peso_kg** – Peso aproximado do equipamento\n",
    "\n",
    "**Nivel_Toxico** – Grau de toxicidade (baixo, médio, alto, crítico)\n",
    "\n",
    "**Custo_Reciclagem_R$** – Estimativa de custo de reciclagem\n",
    "\n",
    "\n",
    "Este notebook tem como objetivo realizar uma análise exploratória e descritiva do dataset `desafio6_lixo_eletronico.csv`, contendo informações sobre descarte de resíduos eletrônicos.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n-6JhhgT8D5"
   },
   "source": [
    "# **:: Base de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YUT18taVzPc"
   },
   "source": [
    "<h4 align=\"justify\">O dataset está disponível para download através do link a seguir:</h4>\n",
    "<h4 align=\"justify\"><a DOWNLOAD href=\"https://drive.google.com/file/d/1mZI1yIT5yJUpw-TWi7du3NfOoaSdT7rt/view?usp=drive_link\" target=\"_blank\" download=\"desafio6_lixo_eletronico.csv\">desafio6_lixo_eletronico.csv</a></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gap3E8utXO6d"
   },
   "source": [
    "## 1. Exploração Inicial dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKjCo_wAXTji"
   },
   "source": [
    "<h4 align=\"justify\">Carregue a base \"desafio6_lixo_eletronico.csv\" em um DataFrame do Pandas, faça uma análise exploratória (shape, tipos de variáveis, estatísticas descritivas) e apresente o total de valores ausentes e duplicados.</h4>\n",
    "\n",
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kctqMs3zX4wQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Registro</th>\n",
       "      <th>Tipo_Eletronico</th>\n",
       "      <th>Ano_Fabricacao</th>\n",
       "      <th>Origem</th>\n",
       "      <th>Destino_Final</th>\n",
       "      <th>Peso_kg</th>\n",
       "      <th>Nivel_Toxico</th>\n",
       "      <th>Custo_Reciclagem_R$</th>\n",
       "      <th>Data_Descarte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Impressora</td>\n",
       "      <td>2006</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Aterro Controlado</td>\n",
       "      <td>30.95</td>\n",
       "      <td>Alto</td>\n",
       "      <td>122.38</td>\n",
       "      <td>2022-03-30 20:08:03.221476512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bateria</td>\n",
       "      <td>2002</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Aterro Controlado</td>\n",
       "      <td>16.89</td>\n",
       "      <td>Alto</td>\n",
       "      <td>48.65</td>\n",
       "      <td>2021-07-14 10:37:51.140939584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Geladeira</td>\n",
       "      <td>2016</td>\n",
       "      <td>Governamental</td>\n",
       "      <td>Cooperativa</td>\n",
       "      <td>32.82</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>165.25</td>\n",
       "      <td>2015-12-30 03:42:16.912751676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Impressora</td>\n",
       "      <td>2021</td>\n",
       "      <td>Governamental</td>\n",
       "      <td>Reciclagem Formal</td>\n",
       "      <td>19.33</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>72.29</td>\n",
       "      <td>2022-07-12 14:20:08.053691264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TV</td>\n",
       "      <td>1997</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Lixão</td>\n",
       "      <td>34.11</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>72.79</td>\n",
       "      <td>2020-01-16 17:04:25.771812064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_Registro Tipo_Eletronico  Ano_Fabricacao         Origem  \\\n",
       "0            1      Impressora            2006         Urbana   \n",
       "1            2         Bateria            2002         Urbana   \n",
       "2            3       Geladeira            2016  Governamental   \n",
       "3            4      Impressora            2021  Governamental   \n",
       "4            5              TV            1997     Industrial   \n",
       "\n",
       "       Destino_Final  Peso_kg Nivel_Toxico  Custo_Reciclagem_R$  \\\n",
       "0  Aterro Controlado    30.95         Alto               122.38   \n",
       "1  Aterro Controlado    16.89         Alto                48.65   \n",
       "2        Cooperativa    32.82        Baixo               165.25   \n",
       "3  Reciclagem Formal    19.33        Baixo                72.29   \n",
       "4              Lixão    34.11        Baixo                72.79   \n",
       "\n",
       "                   Data_Descarte  \n",
       "0  2022-03-30 20:08:03.221476512  \n",
       "1  2021-07-14 10:37:51.140939584  \n",
       "2  2015-12-30 03:42:16.912751676  \n",
       "3  2022-07-12 14:20:08.053691264  \n",
       "4  2020-01-16 17:04:25.771812064  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Leiura dos dados\n",
    "path='/home/akel/PycharmProjects/I2A2/data/raw/'\n",
    "file='desafio6_lixo_eletronico.csv'\n",
    "df = pd.read_csv(path+file)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Analise exploratoria Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE DOS DADOS:\n",
      "Total de linhas: 150\n",
      "Total de colunas: 9\n",
      "Shape completo: (150, 9)\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "  TIPOS DE DADOS:\n",
      "|                     | Data Type   |\n",
      "|:--------------------|:------------|\n",
      "| ID_Registro         | int64       |\n",
      "| Tipo_Eletronico     | object      |\n",
      "| Ano_Fabricacao      | int64       |\n",
      "| Origem              | object      |\n",
      "| Destino_Final       | object      |\n",
      "| Peso_kg             | float64     |\n",
      "| Nivel_Toxico        | object      |\n",
      "| Custo_Reciclagem_R$ | float64     |\n",
      "| Data_Descarte       | object      |\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "VERIFICAÇÃO DE DUPLICATAS:\n",
      "Existem duplicatas? False\n",
      "Total de duplicatas: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "VERIFICAÇÃO DE VALORES NULOS:\n",
      "Existem nulos? True\n",
      "Total de nulos: 75\n",
      "\n",
      "\n",
      "  NULOS POR COLUNA:\n",
      "|                     |   Quantidade de Nulos |\n",
      "|:--------------------|----------------------:|\n",
      "| ID_Registro         |                     0 |\n",
      "| Tipo_Eletronico     |                    15 |\n",
      "| Ano_Fabricacao      |                     0 |\n",
      "| Origem              |                    15 |\n",
      "| Destino_Final       |                    15 |\n",
      "| Peso_kg             |                    15 |\n",
      "| Nivel_Toxico        |                     0 |\n",
      "| Custo_Reciclagem_R$ |                    15 |\n",
      "| Data_Descarte       |                     0 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Informações sobre o shape dos dados\n",
    "print(\"SHAPE DOS DADOS:\")\n",
    "print(f\"Total de linhas: {df.shape[0]}\")\n",
    "print(f\"Total de colunas: {df.shape[1]}\")\n",
    "print(f\"Shape completo: {df.shape}\")\n",
    "print('\\n' + '-'*50 + '\\n')\n",
    "\n",
    "# Informações sobre tipos de dados\n",
    "print(\"  TIPOS DE DADOS:\")\n",
    "print(df.dtypes.to_frame('Data Type').to_markdown())\n",
    "print('\\n' + '-'*50 + '\\n')\n",
    "\n",
    "# Verificação linhas duplicadas\n",
    "print(\"VERIFICAÇÃO DE DUPLICATAS:\")\n",
    "print(f\"Existem duplicatas? {df.duplicated().any()}\")\n",
    "print(f\"Total de duplicatas: {df.duplicated().sum()}\")\n",
    "print('\\n' + '-'*50 + '\\n')\n",
    "\n",
    "# Verificação de valores nulos\n",
    "print(\"VERIFICAÇÃO DE VALORES NULOS:\")\n",
    "print(f\"Existem nulos? {df.isnull().any().any()}\")\n",
    "print(f\"Total de nulos: {df.isnull().sum().sum()}\")\n",
    "print('\\n')\n",
    "\n",
    "# Detalhamento de nulos por coluna\n",
    "print(\"  NULOS POR COLUNA:\")\n",
    "nulos_por_coluna = df.isnull().sum()\n",
    "#nulos_por_coluna = nulos_por_coluna[nulos_por_coluna > 0]  # Mostra apenas colunas com nulos\n",
    "\n",
    "#if len(nulos_por_coluna) > 0:\n",
    "print(nulos_por_coluna.to_frame('Quantidade de Nulos').to_markdown())\n",
    "#else:\n",
    "#print(\"Nenhuma coluna possui valores nulos\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpeza e Padronização\n",
    "Identifique e trate valores inconsistentes (ex.: \"reciclagem formal\" e \"Reciclagem Formal\"), corrija erros de digitação e padronize todas as colunas categóricas. Em seguida, elimine duplicatas mantendo apenas registros válidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Padronização variaveis categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impressora' 'bateria' 'geladeira' 'tv' nan 'computador' 'celular'\n",
      " 'tablet']\n",
      "['urbano' 'governamental' 'industrial' 'rural' nan]\n",
      "['aterro controlado' 'cooperativa' 'reciclagem formal' 'lixão' nan 'rio']\n",
      "['alto' 'baixo' 'médio' 'crítico']\n",
      "Existem duplicatas? False\n"
     ]
    }
   ],
   "source": [
    "# Padronização das variaveis categoricas\n",
    "df['Tipo_Eletronico'] = df['Tipo_Eletronico'].str.lower()\n",
    "df['Origem'] = df['Origem'].str.lower()\n",
    "df['Destino_Final'] = df['Destino_Final'].str.lower()\n",
    "df['Nivel_Toxico'] = df['Nivel_Toxico'].str.lower()\n",
    "\n",
    "df['Origem']=df['Origem'].replace({'urbana': 'urbano'})\n",
    "\n",
    "print(df['Tipo_Eletronico'].unique())\n",
    "print(df['Origem'].unique())\n",
    "print(df['Destino_Final'].unique())\n",
    "print(df['Nivel_Toxico'].unique())\n",
    "\n",
    "print(\"Existem duplicatas?\", df.duplicated().any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Valores nulos\n",
    "Para as variaveis categóricas foi criada uma categoria adicional (\"Desconhecido\") para preservar a informação de que o dado está ausente. Assim, o modelo/estatística pode captar se as informação está correlacionado com outros fatores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis Categóricas\n",
    "df[\"Tipo_Eletronico\"] = df[\"Tipo_Eletronico\"].fillna(\"Desconhecido\")\n",
    "df[\"Origem\"] = df[\"Origem\"].fillna(\"Desconhecido\")\n",
    "df[\"Destino_Final\"] = df[\"Destino_Final\"].fillna(\"Desconhecido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peso_kg_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique    top freq\n",
       "Peso_kg_missing                         \n",
       "0                 135      6  lixão   31\n",
       "1                  15      6  lixão    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peso_kg_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>8</td>\n",
       "      <td>bateria</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>bateria</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique      top freq\n",
       "Peso_kg_missing                           \n",
       "0                 135      8  bateria   21\n",
       "1                  15      7  bateria    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peso_kg_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>governamental</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>urbano</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique            top freq\n",
       "Peso_kg_missing                                 \n",
       "0                 135      5  governamental   42\n",
       "1                  15      5         urbano    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peso_kg_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique    top freq\n",
       "Peso_kg_missing                         \n",
       "0                 135      6  lixão   31\n",
       "1                  15      6  lixão    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peso_kg_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>alto</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>médio</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique    top freq\n",
       "Peso_kg_missing                         \n",
       "0                 135      4   alto   39\n",
       "1                  15      4  médio    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custo_Reciclagem_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>rio</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique    top freq\n",
       "Custo_Reciclagem_missing                         \n",
       "0                          135      6  lixão   31\n",
       "1                           15      5    rio    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custo_Reciclagem_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>8</td>\n",
       "      <td>bateria</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>celular</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique      top freq\n",
       "Custo_Reciclagem_missing                           \n",
       "0                          135      8  bateria   22\n",
       "1                           15      6  celular    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custo_Reciclagem_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>governamental</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique            top freq\n",
       "Custo_Reciclagem_missing                                 \n",
       "0                          135      5  governamental   41\n",
       "1                           15      5          rural    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custo_Reciclagem_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>lixão</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>rio</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique    top freq\n",
       "Custo_Reciclagem_missing                         \n",
       "0                          135      6  lixão   31\n",
       "1                           15      5    rio    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custo_Reciclagem_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>alto</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>médio</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique    top freq\n",
       "Custo_Reciclagem_missing                         \n",
       "0                          135      4   alto   38\n",
       "1                           15      4  médio    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'altoaltobaixobaixobaixomédiobaixoaltoaltobaixobaixocríticoaltomédiocríticobaixoaltobaixomédioaltobaixoaltobaixobaixobaixomédiomédioaltobaixobaixomédiobaixomédiobaixoaltobaixobaixocríticomédiobaixobaixocríticocríticocríticoaltocríticomédiomédiomédiomédiomédioaltocríticomédiocríticobaixomédioaltobaixobaixocríticoaltoaltoaltoaltobaixomédiomédioaltoaltoaltomédiocríticomédiomédiomédiomédiomédiomédioaltoaltoaltoaltomédiocríticobaixomédiobaixocríticoaltocríticomédioaltomédiobaixobaixobaixocríticomédiobaixobaixocríticocríticobaixomédiomédiobaixomédiomédioaltoaltocríticoaltoaltoaltobaixoaltoaltocríticoaltoaltocríticocríticocríticocríticocríticocríticobaixoaltocríticoaltoaltobaixocríticomédio' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m display(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCusto_Reciclagem_missing\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestino_Final\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m     14\u001b[0m display(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCusto_Reciclagem_missing\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNivel_Toxico\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m---> 16\u001b[0m A\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCusto_Reciclagem_missing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNivel_Toxico\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2446\u001b[0m         grouped_mean,\n\u001b[1;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2448\u001b[0m         engine_kwargs,\n\u001b[1;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2450\u001b[0m     )\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/internals/base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[1;32m    366\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    370\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda2025/envs/data_science/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Verificação da aleatoridade dos dados numéricos ausentes\n",
    "df[\"Peso_kg_missing\"] = df[\"Peso_kg\"].isnull().astype(int)\n",
    "df[\"Custo_Reciclagem_missing\"] = df[\"Custo_Reciclagem_R$\"].isnull().astype(int)\n",
    "display(df.groupby(\"Peso_kg_missing\")[\"Destino_Final\"].describe())\n",
    "display(df.groupby(\"Peso_kg_missing\")[\"Tipo_Eletronico\"].describe())\n",
    "display(df.groupby(\"Peso_kg_missing\")[\"Origem\"].describe())\n",
    "display(df.groupby(\"Peso_kg_missing\")[\"Destino_Final\"].describe())\n",
    "display(df.groupby(\"Peso_kg_missing\")[\"Nivel_Toxico\"].describe())\n",
    "\n",
    "display(df.groupby(\"Custo_Reciclagem_missing\")[\"Destino_Final\"].describe())\n",
    "display(df.groupby(\"Custo_Reciclagem_missing\")[\"Tipo_Eletronico\"].describe())\n",
    "display(df.groupby(\"Custo_Reciclagem_missing\")[\"Origem\"].describe())\n",
    "display(df.groupby(\"Custo_Reciclagem_missing\")[\"Destino_Final\"].describe())\n",
    "display(df.groupby(\"Custo_Reciclagem_missing\")[\"Nivel_Toxico\"].describe())\n",
    "\n",
    "A=df.groupby(\"Custo_Reciclagem_missing\")[\"Nivel_Toxico\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                          |   Quantidade de Nulos |\n",
      "|:-------------------------|----------------------:|\n",
      "| ID_Registro              |                     0 |\n",
      "| Tipo_Eletronico          |                     0 |\n",
      "| Ano_Fabricacao           |                     0 |\n",
      "| Origem                   |                     0 |\n",
      "| Destino_Final            |                     0 |\n",
      "| Peso_kg                  |                     0 |\n",
      "| Nivel_Toxico             |                     0 |\n",
      "| Custo_Reciclagem_R$      |                     0 |\n",
      "| Data_Descarte            |                     0 |\n",
      "| Peso_kg_missing          |                     0 |\n",
      "| Custo_Reciclagem_missing |                     0 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variaveis Numéricas\n",
    "\n",
    "def preencher_proporcional(df, col):\n",
    "    valores = df[col].dropna()\n",
    "    probs = valores.value_counts(normalize=True)\n",
    "    n_missing = df[col].isnull().sum()\n",
    "    \n",
    "    imputados = np.random.choice(probs.index, size=n_missing, p=probs.values)\n",
    "    df.loc[df[col].isnull(), col] = imputados\n",
    "    return df\n",
    "\n",
    "for col in [\"Peso_kg\", \"Custo_Reciclagem_R$\"]:\n",
    "    df = preencher_proporcional(df, col)\n",
    "\n",
    "\n",
    "#Verificação\n",
    "nulos_por_coluna = df.isnull().sum()\n",
    "print(nulos_por_coluna.to_frame('Quantidade de Nulos').to_markdown())\n",
    "# Variaveis Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo_Eletronico\n",
      "Bateria       25\n",
      "Geladeira     20\n",
      "Computador    20\n",
      "Celular       20\n",
      "Impressora    18\n",
      "Tablet        17\n",
      "TV            14\n",
      "celular        1\n",
      "Name: count, dtype: int64\n",
      "Origem\n",
      "Governamental    0.333333\n",
      "Urbana           0.251852\n",
      "Industrial       0.207407\n",
      "Rural            0.200000\n",
      "urbano           0.007407\n",
      "Name: count, dtype: float64\n",
      "Destino_Final\n",
      "Lixão                0.251852\n",
      "Aterro Controlado    0.222222\n",
      "Rio                  0.207407\n",
      "Cooperativa          0.177778\n",
      "Reciclagem Formal    0.133333\n",
      "reciclagem formal    0.007407\n",
      "Name: count, dtype: float64\n",
      "Nivel_Toxico\n",
      "Alto       41\n",
      "Baixo      40\n",
      "Médio      39\n",
      "Crítico    30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3-\n",
    "# Frequência por Tipo de Eletrônico\n",
    "freq_tipo = df['Tipo_Eletronico'].value_counts()\n",
    "freq_origem = df['Origem'].value_counts()/135\n",
    "freq_Destino_Final = df['Destino_Final'].value_counts()/135\n",
    "#freq_Peso_kg  = df['Peso_kg'].value_counts()\n",
    "freq_Nivel_Toxico = df['Nivel_Toxico'].value_counts()\n",
    "\n",
    "print(freq_tipo)\n",
    "print(freq_origem)\n",
    "print(freq_Destino_Final)\n",
    "print(freq_Nivel_Toxico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem duplicatas? False\n",
      "Total de duplicatas: 0\n",
      "--------------------------------------\n",
      "Existem Nulos? True\n",
      "Total Nulos: ID_Registro             0\n",
      "Tipo_Eletronico        15\n",
      "Ano_Fabricacao          0\n",
      "Origem                 15\n",
      "Destino_Final          15\n",
      "Peso_kg                15\n",
      "Nivel_Toxico            0\n",
      "Custo_Reciclagem_R$    15\n",
      "dtype: int64\n",
      "Total Nulos            75\n"
     ]
    }
   ],
   "source": [
    "# verificação arquivos duplicados\n",
    "print(\"Existem duplicatas?\", df.duplicated().any())\n",
    "print(\"Total de duplicatas:\", df.duplicated().sum())\n",
    "# verificação arquivos duplicados\n",
    "print('--------------------------------------')\n",
    "print(\"Existem Nulos?\", df.isnull().any().any())\n",
    "print(\"Total Nulos:\", df.isnull().sum())\n",
    "print(\"Total Nulos           \", df.isnull().sum().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
