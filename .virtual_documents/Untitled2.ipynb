from geopy.geocoders import Nominatim
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
import contextily as ctx
import pandas as pd
import seaborn as sns
import folium
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
df= pd.read_csv("Dataset_de_200_Comunidades_para_Analise_Ambiental2.csv")

import warnings

warnings.filterwarnings("ignore", category=FutureWarning)


import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Converter colunas categóricas para numéricas
df['Presença de Escola'] = df['Presença de Escola (Sim/Não)'].map({'Sim': 1, 'Não': 0})
df['Presença de Saúde'] = df['Presença de Unidade de Saúde (Sim/Não)'].map({'Sim': 1, 'Não': 0})

# Selecionar features para clusterização (incluindo coordenadas)
features = [
    'Latitude', 
    'Longitude',
    'Índice de Desmatamento (%)',
    'Acesso à Água Potável (%)',
    'Cobertura Vegetal (%)',
    'Renda Média Mensal (R$)',
    'Densidade Populacional (hab/km²)',
    'Frequência de Queimadas (ano)',
    'Distância de Área Urbana (km)',
    'Presença de Escola',
    'Presença de Saúde'
]

# Normalizar os dados
scaler = StandardScaler()
df_normalizado = pd.DataFrame(scaler.fit_transform(df[features]), columns=features)


# Peso 0.3 para coordenadas (valor entre 0 e 1, ajuste conforme necessidade)
df_normalizado['Latitude'] *= 0.3
df_normalizado['Longitude'] *= 0.3


from sklearn.cluster import KMeans

# Definir número de clusters (use o método do cotovelo para escolher K)
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(df_normalizado)

# Verificar distribuição dos clusters
print(df['Cluster'].value_counts())


# Agrupar por cluster e calcular médias
cluster_stats = df.groupby('Cluster')[features].mean().reset_index()

# Ordenar clusters por vulnerabilidade (ex.: alto desmatamento + baixa renda)
cluster_stats['Score_Vulnerabilidade'] = (
    cluster_stats['Índice de Desmatamento (%)'] * 0.4 +
    (100 - cluster_stats['Acesso à Água Potável (%)']) * 0.3 +
    cluster_stats['Frequência de Queimadas (ano)'] * 0.3
)

cluster_stats = cluster_stats.sort_values('Score_Vulnerabilidade', ascending=False)
print(cluster_stats)


import folium

# Cores para cada cluster (vermelho = mais vulnerável)
cores = {0: 'green', 1: 'orange', 2: 'red'}

# Criar mapa centrado no Brasil
mapa = folium.Map(location=[-15.79, -47.88], zoom_start=4)

# Adicionar marcadores
for _, row in df.iterrows():
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=5,
        color=cores[row['Cluster']],
        fill=True,
        popup=f"""
        <b>{row['Comunidade']}</b><br>
        Cluster: {row['Cluster']}<br>
        Desmatamento: {row['Índice de Desmatamento (%)']}%<br>
        Renda: R${row['Renda Média Mensal (R$)']:,.2f}
        """
    ).add_to(mapa)

# Salvar mapa interativo
mapa



