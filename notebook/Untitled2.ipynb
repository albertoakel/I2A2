{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b02f53-b710-43ec-a541-746bc2c6c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã DATAFRAME ORIGINAL:\n",
      "    ID_Registro Tipo_Eletronico  Ano_Fabricacao       Origem  Peso_kg\n",
      "0             1         Celular            2020  Residencial      0.2\n",
      "1             2        Notebook            2021    Comercial      2.5\n",
      "2             3          Tablet            2022  Residencial      0.6\n",
      "3             1         Celular            2020  Residencial      0.2\n",
      "4             2         Monitor            2019    Comercial      5.0\n",
      "5             4              TV            2020  Residencial      8.0\n",
      "6             5      Impressora            2021    Comercial      4.5\n",
      "7             5      Impressora            2021    Comercial      4.5\n",
      "8             5         Scanner            2022   Industrial      3.2\n",
      "9             6           Mouse            2023  Residencial      0.1\n",
      "10            7         Teclado            2022    Comercial      0.3\n",
      "\n",
      "üìä Total de registros: 11\n",
      "\n",
      "============================================================\n",
      "üîç VERIFICA√á√ÉO DETALHADA DE IDs DUPLICADOS\n",
      "==================================================\n",
      "\n",
      "ID: 5 - 3 registros\n",
      "   Status: DADOS DIFERENTES\n",
      "   Colunas com diferen√ßas: ['Tipo_Eletronico', 'Ano_Fabricacao', 'Origem', 'Peso_kg']\n",
      "\n",
      "ID: 1 - 2 registros\n",
      "   Status: DADOS DIFERENTES\n",
      "   Colunas com diferen√ßas: []\n",
      "\n",
      "ID: 2 - 2 registros\n",
      "   Status: DADOS DIFERENTES\n",
      "   Colunas com diferen√ßas: ['Tipo_Eletronico', 'Ano_Fabricacao', 'Peso_kg']\n",
      "\n",
      "============================================================\n",
      "üîÑ PROCESSANDO DUPLICADOS...\n",
      "‚ö†Ô∏è  Encontrados 7 registros com IDs duplicados\n",
      "\n",
      "Processando ID 1: 2 registros\n",
      "   ‚ûñ Exclu√≠das 1 linhas duplicadas\n",
      "\n",
      "Processando ID 2: 2 registros\n",
      "   üîÑ Linha 4: ID modificado de 2 para 8\n",
      "\n",
      "Processando ID 5: 3 registros\n",
      "   ‚ûñ Exclu√≠das 1 linhas duplicadas\n",
      "   üîÑ Linha 8: ID modificado de 5 para 9\n",
      "\n",
      "============================================================\n",
      "RELAT√ìRIO DO PROCESSAMENTO:\n",
      "‚úÖ Linhas exclu√≠das (duplicados): 2\n",
      "üÜî Novos IDs gerados: 2\n",
      "üìä Total de registros final: 9\n",
      "‚úÖ Verifica√ß√£o final: Nenhum ID duplicado restante\n",
      "\n",
      "============================================================\n",
      "üìã DATAFRAME TRATADO:\n",
      "    ID_Registro Tipo_Eletronico  Ano_Fabricacao       Origem  Peso_kg\n",
      "0             1         Celular            2020  Residencial      0.2\n",
      "1             2        Notebook            2021    Comercial      2.5\n",
      "2             3          Tablet            2022  Residencial      0.6\n",
      "4             8         Monitor            2019    Comercial      5.0\n",
      "5             4              TV            2020  Residencial      8.0\n",
      "6             5      Impressora            2021    Comercial      4.5\n",
      "8             9         Scanner            2022   Industrial      3.2\n",
      "9             6           Mouse            2023  Residencial      0.1\n",
      "10            7         Teclado            2022    Comercial      0.3\n",
      "\n",
      "üìä Total de registros ap√≥s tratamento: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def tratar_ids_duplicados(df, coluna_id='ID_Registro'):\n",
    "    \"\"\"\n",
    "    Verifica IDs duplicados e trata conforme as regras:\n",
    "    - Se dados duplicados: exclui linha\n",
    "    - Se dados diferentes: gera novo ID inteiro √∫nico\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fazer c√≥pia do dataframe para n√£o modificar o original\n",
    "    df_tratado = df.copy()\n",
    "    \n",
    "    # Identificar IDs duplicados\n",
    "    ids_duplicados = df_tratado[df_tratado.duplicated(subset=[coluna_id], keep=False)]\n",
    "    \n",
    "    if ids_duplicados.empty:\n",
    "        print(\"‚úÖ Nenhum ID duplicado encontrado\")\n",
    "        return df_tratado\n",
    "    \n",
    "    print(f\"‚ö†Ô∏è  Encontrados {len(ids_duplicados)} registros com IDs duplicados\")\n",
    "    \n",
    "    # Encontrar o maior ID atual para gerar novos IDs acima dele\n",
    "    max_id = df_tratado[coluna_id].max()\n",
    "    novos_ids_gerados = 0\n",
    "    linhas_excluidas = 0\n",
    "    \n",
    "    # Lista de todos os IDs existentes (para garantir unicidade)\n",
    "    ids_existentes = set(df_tratado[coluna_id].tolist())\n",
    "    \n",
    "    # Processar cada grupo de IDs duplicados\n",
    "    for id_valor, grupo in ids_duplicados.groupby(coluna_id):\n",
    "        if len(grupo) == 1:\n",
    "            continue  # Apenas um registro, n√£o precisa tratar\n",
    "            \n",
    "        print(f\"\\nProcessando ID {id_valor}: {len(grupo)} registros\")\n",
    "        \n",
    "        # Verificar se todos os registros s√£o completamente duplicados\n",
    "        colunas_verificar = [col for col in grupo.columns if col != coluna_id]\n",
    "        duplicados_completos = grupo.duplicated(subset=colunas_verificar, keep='first')\n",
    "        \n",
    "        # Identificar √≠ndices para exclus√£o e modifica√ß√£o\n",
    "        indices_para_excluir = []\n",
    "        indices_para_modificar = []\n",
    "        \n",
    "        for idx, is_duplicado in duplicados_completos.items():\n",
    "            if is_duplicado:\n",
    "                indices_para_excluir.append(idx)\n",
    "            else:\n",
    "                indices_para_modificar.append(idx)\n",
    "        \n",
    "        # Excluir registros duplicados (mant√©m apenas o primeiro de cada grupo duplicado)\n",
    "        if indices_para_excluir:\n",
    "            df_tratado = df_tratado.drop(indices_para_excluir)\n",
    "            linhas_excluidas += len(indices_para_excluir)\n",
    "            print(f\"   ‚ûñ Exclu√≠das {len(indices_para_excluir)} linhas duplicadas\")\n",
    "        \n",
    "        # Gerar novos IDs para registros com dados diferentes\n",
    "        if indices_para_modificar:\n",
    "            # Pular o primeiro registro (mant√©m o ID original)\n",
    "            indices_para_modificar = indices_para_modificar[1:] if indices_para_modificar else []\n",
    "            \n",
    "            for idx in indices_para_modificar:\n",
    "                # Gerar novo ID inteiro √∫nico\n",
    "                novo_id = max_id + 1\n",
    "                while novo_id in ids_existentes:\n",
    "                    novo_id += 1\n",
    "                \n",
    "                # Atualizar o ID\n",
    "                df_tratado.loc[idx, coluna_id] = novo_id\n",
    "                ids_existentes.add(novo_id)\n",
    "                max_id = max(max_id, novo_id)\n",
    "                novos_ids_gerados += 1\n",
    "                \n",
    "                print(f\"   üîÑ Linha {idx}: ID modificado de {id_valor} para {novo_id}\")\n",
    "    \n",
    "    # Relat√≥rio final\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RELAT√ìRIO DO PROCESSAMENTO:\")\n",
    "    print(f\"‚úÖ Linhas exclu√≠das (duplicados): {linhas_excluidas}\")\n",
    "    print(f\"üÜî Novos IDs gerados: {novos_ids_gerados}\")\n",
    "    print(f\"üìä Total de registros final: {len(df_tratado)}\")\n",
    "    \n",
    "    # Verificar se ainda h√° duplicados ap√≥s o tratamento\n",
    "    duplicados_finais = df_tratado[df_tratado.duplicated(subset=[coluna_id], keep=False)]\n",
    "    if duplicados_finais.empty:\n",
    "        print(\"‚úÖ Verifica√ß√£o final: Nenhum ID duplicado restante\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  ATEN√á√ÉO: Ainda existem {len(duplicados_finais)} IDs duplicados\")\n",
    "    \n",
    "    return df_tratado\n",
    "\n",
    "def verificar_duplicados_detalhado(df, coluna_id='ID_Registro'):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para verificar detalhadamente os IDs duplicados\n",
    "    \"\"\"\n",
    "    print(\"üîç VERIFICA√á√ÉO DETALHADA DE IDs DUPLICADOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Identificar IDs duplicados\n",
    "    ids_duplicados = df[df.duplicated(subset=[coluna_id], keep=False)]\n",
    "    \n",
    "    if ids_duplicados.empty:\n",
    "        print(\"Nenhum ID duplicado encontrado\")\n",
    "        return\n",
    "    \n",
    "    # Contar por ID\n",
    "    contagem = ids_duplicados[coluna_id].value_counts()\n",
    "    \n",
    "    for id_valor, quantidade in contagem.items():\n",
    "        registros = df[df[coluna_id] == id_valor]\n",
    "        \n",
    "        print(f\"\\nID: {id_valor} - {quantidade} registros\")\n",
    "        \n",
    "        # Verificar se s√£o completamente duplicados\n",
    "        colunas_dados = [col for col in registros.columns if col != coluna_id]\n",
    "        duplicados_exatos = registros.duplicated(subset=colunas_dados).all()\n",
    "        \n",
    "        if duplicados_exatos:\n",
    "            print(\"   Status: DUPLICADOS COMPLETOS (dados id√™nticos)\")\n",
    "        else:\n",
    "            print(\"   Status: DADOS DIFERENTES\")\n",
    "            # Mostrar colunas com diferen√ßas\n",
    "            colunas_diff = registros.columns[registros.nunique() > 1]\n",
    "            print(f\"   Colunas com diferen√ßas: {list(colunas_diff)}\")\n",
    "\n",
    "# Exemplo de uso completo\n",
    "def exemplo_completo():\n",
    "    # Criar dados de exemplo para teste\n",
    "    dados_exemplo = {\n",
    "        'ID_Registro': [1, 2, 3, 1, 2, 4, 5, 5, 5, 6, 7],\n",
    "        'Tipo_Eletronico': ['Celular', 'Notebook', 'Tablet', 'Celular', 'Monitor', \n",
    "                           'TV', 'Impressora', 'Impressora', 'Scanner', 'Mouse', 'Teclado'],\n",
    "        'Ano_Fabricacao': [2020, 2021, 2022, 2020, 2019, \n",
    "                          2020, 2021, 2021, 2022, 2023, 2022],\n",
    "        'Origem': ['Residencial', 'Comercial', 'Residencial', 'Residencial', 'Comercial',\n",
    "                  'Residencial', 'Comercial', 'Comercial', 'Industrial', 'Residencial', 'Comercial'],\n",
    "        'Peso_kg': [0.2, 2.5, 0.6, 0.2, 5.0, 8.0, 4.5, 4.5, 3.2, 0.1, 0.3]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dados_exemplo)\n",
    "    \n",
    "    print(\"üìã DATAFRAME ORIGINAL:\")\n",
    "    print(df)\n",
    "    print(f\"\\nüìä Total de registros: {len(df)}\")\n",
    "    \n",
    "    # Verificar duplicados detalhadamente\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    verificar_duplicados_detalhado(df, 'ID_Registro')\n",
    "    \n",
    "    # Tratar duplicados\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîÑ PROCESSANDO DUPLICADOS...\")\n",
    "    df_tratado = tratar_ids_duplicados(df, 'ID_Registro')\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã DATAFRAME TRATADO:\")\n",
    "    print(df_tratado)\n",
    "    print(f\"\\nüìä Total de registros ap√≥s tratamento: {len(df_tratado)}\")\n",
    "    \n",
    "    return df_tratado\n",
    "\n",
    "# Para usar com seus dados reais:\n",
    "# df = pd.read_csv('seu_arquivo.csv')  # ou seu dataframe\n",
    "# verificar_duplicados_detalhado(df, 'ID_Registro')\n",
    "# df_tratado = tratar_ids_duplicados(df, 'ID_Registro')\n",
    "\n",
    "# Executar exemplo\n",
    "if __name__ == \"__main__\":\n",
    "    df_resultado = exemplo_completo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f7132-145c-4060-9937-d9bbd8ce3d87",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Propostas\n",
    "\n",
    "1. **Pontos de Coleta Segmentados**\n",
    "   * Centros urbanos: coleta de computadores, celulares e impressoras.\n",
    "   * Munic√≠pios rurais: coleta de baterias, TVs e geladeiras.\n",
    "   * Rotas log√≠sticas otimizadas para transporte seguro de equipamentos pesados e t√≥xicos\n",
    "2. **Campanhas Integradas de Educa√ß√£o Ambiental**\n",
    "    * Associadas √† localiza√ß√£o de pontos de coleta.\n",
    "    * Foco em conscientiza√ß√£o sobre riscos de metais pesados e destinos corretos.\n",
    "3. **Pol√≠ticas de Incentivo e Responsabilidade do Fabricante**\n",
    "    * Subs√≠dios ou cr√©ditos para √≥rg√£os governamentais e empresas privadas que realizem descarte formal.\n",
    "    * Parcerias com cooperativas e recicladores locais.\n",
    "    * Adapta√ß√£o de modelos de EPR inspirados em pa√≠ses como Alemanha, Jap√£o e Coreia do Sul, responsabilizando fabricantes pelo destino final seguro de seus produtos\n",
    "4. **Monitoramento Din√¢mico**\n",
    "   * Dashboards integrando origem, tipo, peso, destino e risco.\n",
    "   * Identifica√ß√£o de munic√≠pios priorit√°rios para interven√ß√£o r√°pida.\n",
    "   * Avalia√ß√£o cont√≠nua do impacto das campanhas e ajustes de rotas log√≠sticas.\n",
    "5. **Planejamento Regional Diferenciado**\n",
    "    * Estrat√©gias espec√≠ficas para grandes centros urbanos, munic√≠pios m√©dios e rurais.\n",
    "    * Foco em redu√ß√£o de descarte informal em √°reas cr√≠ticas, sem negligenciar munic√≠pios menores que apresentam boas pr√°ticas.\n",
    "\n",
    "O estudo evidencia que a gest√£o do lixo eletr√¥nico na Amaz√¥nia deve ser multidimensional, considerando simultaneamente tipo de eletr√¥nico, origem do res√≠duo, peso, risco t√≥xico, educa√ß√£o ambiental e infraestrutura log√≠stica. A integra√ß√£o desses fatores permite identificar padr√µes de risco, alocar recursos de forma estrat√©gica e aumentar a taxa de descarte formal. A proposta de pontos de coleta segmentados, associada a campanhas educativas e monitoramento din√¢mico, constitui uma abordagem pr√°tica e realista para reduzir impactos ambientais e proteger a sa√∫de das popula√ß√µes amaz√¥nicas. O relat√≥rio refor√ßa que pol√≠ticas p√∫blicas isoladas n√£o s√£o suficientes; apenas uma abordagem integrada e orientada por dados pode transformar informa√ß√£o em a√ß√£o eficaz, contribuindo para a preserva√ß√£o ambiental e para o cumprimento das metas de sustentabilidade na regi√£o amaz√¥nica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4ed77-bd7d-4a75-b5db-32f934ba2405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
